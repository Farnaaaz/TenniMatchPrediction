{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0           0\n",
      "Location             0\n",
      "Date                 0\n",
      "Round                0\n",
      "Winner               0\n",
      "Loser                0\n",
      "WRank               60\n",
      "LRank              206\n",
      "W_hand               0\n",
      "W_ht               957\n",
      "W_nationality      858\n",
      "W_age              859\n",
      "L_hand               0\n",
      "L_ht              1102\n",
      "L_nationality      791\n",
      "L_age              796\n",
      "L_wt             11818\n",
      "W_wt             11801\n",
      "dtype: int64\n",
      "19922\n"
     ]
    }
   ],
   "source": [
    "first_df1 = pd.read_csv(\"modeling data/1_players_info_added_Clean_data.csv\")\n",
    "df1_nulls = first_df1.isnull().sum()\n",
    "print(df1_nulls)\n",
    "print(len(first_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7399"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop_nulls = first_df1.copy()\n",
    "df_drop_nulls = df_drop_nulls.dropna()\n",
    "len(df_drop_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17917"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_dropped_wt = first_df1.copy()\n",
    "df1_dropped_wt.drop(columns=[\"Unnamed: 0\",'L_wt', 'W_wt'], inplace=True)\n",
    "df1_no_nulls = df1_dropped_wt.dropna()\n",
    "len(df1_no_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addingWinnerColumn(df):\n",
    "    df_winner = df.copy()\n",
    "    df_loser = df.copy()\n",
    "\n",
    "    df_winner['win'] = 1\n",
    "    df_loser['win'] = 0\n",
    "\n",
    "    # Renaming columns to 'player' and 'opponent' for winners\n",
    "    df_winner.rename(columns={\n",
    "        'Winner': 'player',\n",
    "        'Loser': 'opponent',\n",
    "        'WRank': 'player_rank',\n",
    "        'LRank': 'opponent_rank',\n",
    "        'W_hand': 'player_hand',\n",
    "        'L_hand': 'opponent_hand',\n",
    "        'W_ht': 'player_ht', \n",
    "        'W_nationality':'player_nationality', \n",
    "        'W_age':'player_age', \n",
    "        'L_ht':'opponent_ht',\n",
    "        'L_nationality':'opponent_nationality', \n",
    "        'L_age':'opponent_age'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Renaming columns to 'player' and 'opponent' for losers\n",
    "    df_loser.rename(columns={\n",
    "        'Winner': 'opponent',\n",
    "        'Loser': 'player',\n",
    "        'WRank': 'opponent_rank',\n",
    "        'LRank': 'player_rank',\n",
    "        'W_hand': 'opponent_hand',\n",
    "        'L_hand': 'player_hand',\n",
    "        'W_ht':'opponent_ht', \n",
    "        'W_nationality':'opponent_nationality', \n",
    "        'W_age':'opponent_age', \n",
    "        'L_ht':'player_ht',\n",
    "        'L_nationality':'player_nationality',\n",
    "        'L_age':'player_age'\n",
    "    }, inplace=True)\n",
    "    df_transformed = pd.concat([df_winner, df_loser], ignore_index=True)\n",
    "    df_transformed = df_transformed.sample(frac=1).reset_index(drop=True)\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixPlayerRank(df):\n",
    "    df_transformed = df.copy()\n",
    "    player_peak_ranking = df_transformed.groupby('player')['player_rank'].min().reset_index()\n",
    "    opponent_peak_ranking = df_transformed.groupby('opponent')['opponent_rank'].min().reset_index()\n",
    "    player_peak_ranking\n",
    "\n",
    "    player_updated = pd.merge(df_transformed, player_peak_ranking[['player', 'player_rank']], on='player', how='left')\n",
    "    opponent_updated = pd.merge(player_updated, opponent_peak_ranking[['opponent', 'opponent_rank']], on='opponent', how='left')\n",
    "    df1 = opponent_updated.copy()\n",
    "    df1.drop(columns=['player_rank_x', 'opponent_rank_x'], inplace=True)\n",
    "    df1 = df1.rename(columns={  'player_rank_y': 'player_rank',\n",
    "                                'opponent_rank_y': 'opponent_rank'})\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryList = [\n",
    "    [\"AUS\", \"Australia\", \"Canberra\", \"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\"],\n",
    "    [\"IND\", \"India\", \"New Delhi\", \"Mumbai\", \"Kolkata\", \"Chennai\", \"Bangalore\", \"Hyderabad\", \"Pune\"],\n",
    "    [\"QAT\", \"Qatar\", \"Doha\"],\n",
    "    [\"NZL\", \"New Zealand\", \"Wellington\", \"Auckland\", \"Christchurch\"],\n",
    "    [\"FRA\", \"France\", \"Paris\", \"Marseille\", \"Lyon\", \"Toulouse\", \"Nice\", \"Nantes\", \"Strasbourg\", \"Montpellier\", \"Bordeaux\", \"Lille\",\"Roland Garros\",\"Metz\"],\n",
    "    [\"ECU\", \"Ecuador\", \"Quito\", \"Guayaquil\"],\n",
    "    [\"BGR\", \"Bulgaria\", \"Sofia\", \"Plovdiv\", \"Varna\"],\n",
    "    [\"ARG\", \"Argentina\", \"Buenos Aires\", \"Cordoba\", \"Rosario\", \"Mendoza\"],\n",
    "    [\"USA\", \"US\", \"United States\", \"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Antonio\", \"San Diego\", \"Dallas\", \"Salem\", \"Cincinnati\",\"Newport\",'Atlanta','Washington','Memphis',\"Delray Beach\",\"Miami\"],\n",
    "    [\"BRA\", \"Brazil\", \"Brasília\", \"São Paulo\", \"Sao Paulo\",\"Rio de Janeiro\",\"Rio\", \"Salvador\", \"Fortaleza\", \"Belo Horizonte\"],\n",
    "    [\"MEX\", \"Mexico\", \"Mexico City\", \"Guadalajara\", \"Monterrey\", \"Puebla\", \"Toluca\", \"Tijuana\",\"Acapulco\",\"Los Cabos\"],\n",
    "    [\"ARE\", \"United Arab Emirates\", \"Abu Dhabi\", \"Dubai\", \"Sharjah\"],\n",
    "    [\"MAR\", \"Morocco\", \"Rabat\", \"Casablanca\", \"Fez\", \"Marrakech\"],\n",
    "    [\"MCO\", \"Monaco\", \"Monte Carlo\"],\n",
    "    [\"ESP\", \"Spain\", \"Madrid\", \"Barcelona\", \"Valencia\", \"Seville\", \"Zaragoza\"],\n",
    "    [\"HUN\", \"Hungary\", \"Budapest\"],\n",
    "    [\"PRT\", \"Portugal\", \"Lisbon\", \"Porto\", \"Amadora\", \"Braga\",\"Estoril\"],\n",
    "    [\"TUR\", \"Turkey\", \"Ankara\", \"Istanbul\", \"Izmir\", \"Bursa\", \"Antalya\"],\n",
    "    [\"DEU\", \"Germany\", \"Berlin\", \"Hamburg\", \"Munich\", \"Cologne\", \"Frankfurt\", \"Stuttgart\", \"Düsseldorf\",\"Dusseldorf\", \"Dortmund\", \"Essen\", \"Leipzig\",\"Halle\"],\n",
    "    [\"ITA\", \"Italy\", \"Rome\", \"Milan\", \"Naples\", \"Turin\", \"Palermo\", \"Genoa\", \"Bologna\", \"Florence\",\"nitto\",\"Sardinia\"],\n",
    "    [\"CHE\", \"Switzerland\", \"Zurich\", \"Geneva\", \"Basel\", \"Lausanne\",\"Gstaad\"],\n",
    "    [\"NLD\", \"Netherlands\", \"Amsterdam\", \"Rotterdam\", \"The Hague\", \"Utrecht\",\"s Hertogenbosch\"],\n",
    "    [\"GBR\", \"United Kingdom\", \"London\", \"Birmingham\", \"Glasgow\", \"Liverpool\", \"Leeds\", \"Sheffield\", \"Edinburgh\", \"Bristol\", \"Manchester\",\"Eastbourne\",\"wimbledon\"],\n",
    "    [\"SWE\", \"Sweden\", \"Stockholm\", \"Gothenburg\", \"Malmö\",\"Malmo\", \"Uppsala\",'bastad'],\n",
    "    [\"HRV\", \"Croatia\", \"Zagreb\", \"Split\", \"Rijeka\",'Umag'],\n",
    "    [\"CHN\", \"China\", \"Beijing\", \"Shanghai\", \"Chongqing\", \"Tianjin\", \"Guangzhou\", \"Shenzhen\", \"Chengdu\",\"Zhuhai\"],\n",
    "    [\"BEL\", \"Belgium\", \"Brussels\", \"Antwerp\", \"Ghent\", \"Charleroi\", \"Liège\"],\n",
    "    [\"RUS\", \"Russia\", \"Moscow\", \"Saint Petersburg\",\"st petersburg\",\"Petersburg\" \"Novosibirsk\", \"Yekaterinburg\", \"Nizhny Novgorod\"],\n",
    "    [\"CHL\", \"Chile\", \"Santiago\"],\n",
    "    [\"CAN\", \"Canada\", \"Ottawa\", \"Toronto\", \"Montreal\", \"Calgary\", \"Edmonton\", \"Vancouver\", \"Winnipeg\", \"Quebec City\", \"Hamilton\", \"Kitchener\"],\n",
    "    [\"KAZ\", \"Kazakhstan\", \"Nur Sultan\", \"Almaty\"],\n",
    "    [\"AUT\", \"Austria\", \"Vienna\",\"Kitzbuhel\"],\n",
    "    [\"JPN\", \"Japan\", \"Tokyo\", \"Yokohama\", \"Osaka\", \"Nagoya\", \"Sapporo\", \"Fukuoka\", \"Kobe\", \"Kyoto\"],\n",
    "    [\"Unknown\", \"Davis\",\"Club\",'Cup', 'Tour Finals',\"NextGen\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fixCountryName(df):\n",
    "    newCountryName = df.copy()\n",
    "    newCountryName[\"Location\"] = newCountryName[\"Location\"].str.replace('_',\" \")\n",
    "    newCountryName[\"Location\"] = newCountryName[\"Location\"].str.replace('-',\" \")\n",
    "\n",
    "    for country in countryList:\n",
    "        for i in range(len(country)):\n",
    "            newCountryName[\"Location\"] = newCountryName[\"Location\"].str.replace('.*'+country[i]+'.*', country[0], flags=re.IGNORECASE, regex=True)\n",
    "    return newCountryName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isHomeCountry(df):\n",
    "    df1_home_country = df.copy()\n",
    "    df1_home_country['is_player_home_country'] = np.equal(df1_home_country['Location'], df1_home_country['player_nationality'])\n",
    "    df1_home_country['is_opponent_home_country'] = np.equal(df1_home_country['Location'], df1_home_country['opponent_nationality'])\n",
    "    df1_home_country.drop(columns=[\"Location\",'player_nationality', 'opponent_nationality'], inplace=True)\n",
    "    return df1_home_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date(df):\n",
    "    df1 = df.copy()\n",
    "    df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "    df1['year'] = df1['Date'].dt.year\n",
    "    df1['month'] = df1['Date'].dt.month\n",
    "    df1['day'] = df1['Date'].dt.day\n",
    "    df1['dayofweek'] = df1['Date'].dt.dayofweek\n",
    "    df1.drop(columns=[\"Date\"], inplace=True)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startToHome(df):\n",
    "    df_target = df.copy()\n",
    "    df_target_win = addingWinnerColumn(df_target)\n",
    "    df_target_player = fixPlayerRank(df_target_win)\n",
    "    df_target_country = fixCountryName(df_target_player)\n",
    "    df_target_home = isHomeCountry(df_target_country)\n",
    "    df_target_dates = split_date(df_target_home)\n",
    "    return df_target_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Round</th>\n",
       "      <th>player</th>\n",
       "      <th>opponent</th>\n",
       "      <th>player_hand</th>\n",
       "      <th>player_ht</th>\n",
       "      <th>player_age</th>\n",
       "      <th>opponent_hand</th>\n",
       "      <th>opponent_ht</th>\n",
       "      <th>opponent_age</th>\n",
       "      <th>...</th>\n",
       "      <th>W_wt</th>\n",
       "      <th>win</th>\n",
       "      <th>player_rank</th>\n",
       "      <th>opponent_rank</th>\n",
       "      <th>is_player_home_country</th>\n",
       "      <th>is_opponent_home_country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1649</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>Querrey S.</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>R</td>\n",
       "      <td>198.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>R</td>\n",
       "      <td>198.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4306</td>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Fognini F.</td>\n",
       "      <td>Ymer M.</td>\n",
       "      <td>R</td>\n",
       "      <td>178.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>R</td>\n",
       "      <td>183.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6562</td>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>Albot R.</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>175.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7021</td>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Fabbiano T.</td>\n",
       "      <td>Sonego L.</td>\n",
       "      <td>R</td>\n",
       "      <td>173.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>R</td>\n",
       "      <td>191.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7198</td>\n",
       "      <td>Round of 32</td>\n",
       "      <td>Maden Y.</td>\n",
       "      <td>Kicker N.</td>\n",
       "      <td>R</td>\n",
       "      <td>185.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>R</td>\n",
       "      <td>178.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39839</th>\n",
       "      <td>2230</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Mahut N.</td>\n",
       "      <td>Querrey S.</td>\n",
       "      <td>R</td>\n",
       "      <td>191.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>R</td>\n",
       "      <td>198.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39840</th>\n",
       "      <td>1950</td>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Herbert P.</td>\n",
       "      <td>Shapovalov D.</td>\n",
       "      <td>R</td>\n",
       "      <td>188.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>L</td>\n",
       "      <td>185.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39841</th>\n",
       "      <td>4853</td>\n",
       "      <td>Round of 32</td>\n",
       "      <td>Cervantes I.</td>\n",
       "      <td>Olivo R.</td>\n",
       "      <td>R</td>\n",
       "      <td>183.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>R</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39842</th>\n",
       "      <td>6809</td>\n",
       "      <td>Round of 128</td>\n",
       "      <td>Kyrgios N.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>R</td>\n",
       "      <td>193.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>R</td>\n",
       "      <td>183.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39843</th>\n",
       "      <td>1945</td>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Edmund K.</td>\n",
       "      <td>Kyrgios N.</td>\n",
       "      <td>R</td>\n",
       "      <td>188.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>R</td>\n",
       "      <td>193.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39844 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         Round        player       opponent player_hand  \\\n",
       "0            1649    Semifinals    Querrey S.       Cilic M.           R   \n",
       "1            4306   Round of 64    Fognini F.        Ymer M.           R   \n",
       "2            6562   Round of 64   Struff J.L.       Albot R.           U   \n",
       "3            7021   Round of 64   Fabbiano T.      Sonego L.           R   \n",
       "4            7198   Round of 32      Maden Y.      Kicker N.           R   \n",
       "...           ...           ...           ...            ...         ...   \n",
       "39839        2230   Round of 16      Mahut N.     Querrey S.           R   \n",
       "39840        1950   Round of 64    Herbert P.  Shapovalov D.           R   \n",
       "39841        4853   Round of 32  Cervantes I.       Olivo R.           R   \n",
       "39842        6809  Round of 128    Kyrgios N.    Thompson J.           R   \n",
       "39843        1945   Round of 64     Edmund K.     Kyrgios N.           R   \n",
       "\n",
       "       player_ht  player_age opponent_hand  opponent_ht  opponent_age  ...  \\\n",
       "0          198.0        31.2             R        198.0          30.2  ...   \n",
       "1          178.0        31.6             R        183.0          20.5  ...   \n",
       "2            NaN         NaN             R        175.0          29.1  ...   \n",
       "3          173.0        29.6             R        191.0          23.7  ...   \n",
       "4          185.0        35.0             R        178.0          32.0  ...   \n",
       "...          ...         ...           ...          ...           ...  ...   \n",
       "39839      191.0        42.0             R        198.0          37.0  ...   \n",
       "39840      188.0        28.3             L        185.0          20.3  ...   \n",
       "39841      183.0        35.0             R        180.0          32.0  ...   \n",
       "39842      193.0        23.6             R        183.0          24.6  ...   \n",
       "39843      188.0        24.5             R        193.0          24.2  ...   \n",
       "\n",
       "       W_wt  win  player_rank  opponent_rank  is_player_home_country  \\\n",
       "0       NaN    0         11.0            3.0                   False   \n",
       "1       NaN    1          9.0           67.0                   False   \n",
       "2       NaN    1         33.0           39.0                   False   \n",
       "3       NaN    1         70.0           32.0                   False   \n",
       "4      68.0    1        109.0           84.0                   False   \n",
       "...     ...  ...          ...            ...                     ...   \n",
       "39839  95.0    0         38.0           11.0                   False   \n",
       "39840   NaN    0         36.0           11.0                   False   \n",
       "39841  73.0    0        125.0           79.0                   False   \n",
       "39842   NaN    1         13.0           43.0                   False   \n",
       "39843   NaN    1         14.0           13.0                   False   \n",
       "\n",
       "       is_opponent_home_country  year  month  day  dayofweek  \n",
       "0                         False  2017      7   14          4  \n",
       "1                          True  2018      7   19          3  \n",
       "2                         False  2019      5   30          3  \n",
       "3                         False  2019      7   24          2  \n",
       "4                         False  2017      1    1          6  \n",
       "...                         ...   ...    ...  ...        ...  \n",
       "39839                     False  2016      1    1          4  \n",
       "39840                      True  2019      8    5          0  \n",
       "39841                     False  2017      1    1          6  \n",
       "39842                     False  2019      7    2          1  \n",
       "39843                     False  2019      8    5          0  \n",
       "\n",
       "[39844 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_home = pd.read_csv(\"modeling data/df1_with_home.csv\")\n",
    "df_home = startToHome(df1_no_nulls)\n",
    "df_drop_nulls = startToHome(df_drop_nulls)\n",
    "\n",
    "raw_df = startToHome(first_df1)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in column 'player_ht': [], Count: 0\n",
      "Outliers in column 'player_age': [], Count: 0\n",
      "Outliers in column 'opponent_ht': [], Count: 0\n",
      "Outliers in column 'opponent_age': [], Count: 0\n",
      "Outliers in column 'player_rank': [5, 16, 52, 61, 80, 131, 166, 193, 224, 231, 249, 275, 310, 332, 333, 359, 384, 403, 414, 467, 504, 573, 588, 593, 605, 624, 628, 652, 796, 805, 839, 840, 846, 854, 863, 892, 893, 903, 911, 928, 958, 964, 974, 994, 1006, 1012, 1018, 1036, 1077, 1129, 1168, 1198, 1217, 1313, 1333, 1369, 1386, 1397, 1485, 1495, 1528, 1535, 1570, 1576, 1583, 1595, 1616, 1643, 1714, 1775, 1783, 1881, 1886, 1904, 1922, 1997, 2010, 2011, 2014, 2129, 2179, 2202, 2208, 2221, 2301, 2303, 2307, 2318, 2332, 2344, 2352, 2363, 2434, 2446, 2451, 2460, 2462, 2593, 2637, 2651, 2678, 2697, 2741, 2754, 2861, 2887, 2894, 2910, 2926, 2986, 3005, 3023, 3027, 3046, 3071, 3076, 3091, 3125, 3159, 3184, 3201, 3206, 3208, 3213, 3231, 3249, 3262, 3281, 3296, 3349, 3391, 3434, 3454, 3485, 3542, 3556, 3598, 3606, 3616, 3665, 3685, 3690, 3735, 3851, 3878, 3897, 3936, 3963, 3982, 3999, 4001, 4029, 4047, 4127, 4142, 4248, 4357, 4376, 4472, 4506, 4530, 4560, 4561, 4567, 4572, 4612, 4637, 4658, 4707, 4755, 4760, 4764, 4838, 4890, 4892, 4928, 4950, 4995, 5013, 5053, 5129, 5133, 5157, 5178, 5179, 5299, 5301, 5337, 5339, 5391, 5394, 5458, 5524, 5533, 5534, 5574, 5595, 5607, 5616, 5688, 5703, 5765, 5777, 5793, 5889, 5896, 5905, 5911, 5941, 5950, 5953, 5999, 6006, 6008, 6034, 6043, 6096, 6147, 6226, 6236, 6249, 6251, 6274, 6309, 6323, 6328, 6339, 6370, 6378, 6391, 6440, 6444, 6456, 6464, 6479, 6514, 6534, 6551, 6564, 6596, 6640, 6659, 6662, 6677, 6711, 6758, 6836, 6843, 6849, 6852, 6856, 6861, 6870, 6901, 6989, 7000, 7019, 7069, 7213, 7301, 7470, 7486, 7500, 7515, 7535, 7548, 7553, 7562, 7764, 7780, 7826, 7834, 7842, 7849, 7909, 7916, 7918, 7922, 7949, 7992, 8001, 8025, 8035, 8089, 8101, 8126, 8152, 8185, 8215, 8252, 8294, 8295, 8330, 8340, 8365, 8391, 8423, 8465, 8471, 8484, 8498, 8532, 8549, 8562, 8681, 8691, 8776, 8880, 8913, 9023, 9052, 9053, 9057, 9061, 9067, 9072, 9137, 9152, 9174, 9193, 9247, 9262, 9274, 9317, 9322, 9339, 9435, 9532, 9601, 9615, 9634, 9661, 9662, 9720, 9726, 9731, 9759, 9788, 9796, 9823, 9828, 9874, 9892, 9898, 9924, 9957, 9963, 9990, 10007, 10022, 10064, 10075, 10078, 10085, 10145, 10165, 10166, 10173, 10310, 10367, 10390, 10399, 10400, 10437, 10456, 10464, 10488, 10570, 10576, 10580, 10625, 10642, 10649, 10699, 10721, 10725, 10758, 10772, 10838, 10853, 10912, 10919, 10925, 10937, 11109, 11138, 11160, 11165, 11219, 11234, 11251, 11324, 11342, 11345, 11363, 11366, 11437, 11490, 11547, 11686, 11691, 11709, 11729, 11731, 11809, 11820, 11850, 11852, 11867, 11868, 11881, 11925, 11938, 11943, 11945, 11967, 11970, 12009, 12027, 12089, 12173, 12180, 12186, 12224, 12276, 12304, 12338, 12339, 12412, 12443, 12464, 12635, 12637, 12648, 12672, 12678, 12795, 12828, 12854, 12856, 12909, 12938, 12945, 12972, 12979, 12993, 12994, 13009, 13054, 13080, 13095, 13166, 13167, 13181, 13186, 13229, 13286, 13300, 13315, 13372, 13379, 13386, 13415, 13433, 13457, 13493, 13508, 13529, 13541, 13546, 13550, 13578, 13620, 13632, 13644, 13676, 13678, 13684, 13697, 13714, 13728, 13730, 13731, 13774, 13840, 13841, 13881, 13987, 14002, 14008, 14030, 14053, 14090, 14119, 14129, 14130, 14132, 14189, 14193, 14214, 14304, 14305, 14350, 14392, 14394, 14440, 14444, 14452, 14479, 14524, 14560, 14585, 14597, 14600, 14641, 14648, 14652, 14653, 14654, 14665, 14691, 14702, 14759, 14807, 14834, 14848, 14899, 14939, 14984, 15039, 15057, 15079, 15130, 15141, 15147, 15201, 15209, 15213, 15273, 15288, 15292, 15336, 15370, 15375, 15413, 15442, 15474, 15488, 15519, 15578, 15654, 15671, 15690, 15723, 15757, 15777, 15804, 15812, 15867, 15881, 15883, 15894, 15901, 15902, 15950, 16060, 16098, 16108, 16111, 16128, 16213, 16226, 16250, 16294, 16307, 16308, 16313, 16354, 16395, 16405, 16413, 16457, 16595, 16656, 16683, 16712, 16765, 16778, 16795, 16806, 16844, 16884, 16895, 16917, 16933, 16945, 16995, 16999, 17011, 17017, 17118, 17131, 17133, 17179, 17191, 17205, 17224, 17234, 17251, 17339, 17440, 17457, 17460, 17468, 17484, 17488, 17505, 17510, 17584, 17617, 17655, 17704, 17720, 17759, 17761, 17767, 17788, 17799, 17806, 17808, 17831, 17834, 17846, 17873, 17876, 17890, 17976, 17997, 18014, 18015, 18026, 18065, 18074, 18133, 18186, 18202, 18236, 18257, 18269, 18302, 18311, 18324, 18332, 18346, 18354, 18406, 18417, 18438, 18455, 18479, 18518, 18526, 18586, 18593, 18608, 18624, 18686, 18719, 18787, 18802, 18825, 18908, 18928, 18934, 18935, 18960, 18982, 19005, 19042, 19108, 19117, 19136, 19174, 19206, 19271, 19307, 19387, 19396, 19471, 19495, 19524, 19547, 19571, 19605, 19606, 19617, 19669, 19672, 19688, 19697, 19761, 19767, 19777, 19785, 19790, 19880, 19941, 19979, 19993, 20003, 20020, 20050, 20054, 20084, 20102, 20104, 20105, 20140, 20150, 20187, 20201, 20318, 20329, 20352, 20363, 20398, 20405, 20432, 20433, 20523, 20537, 20560, 20591, 20624, 20649, 20656, 20710, 20712, 20715, 20759, 20789, 20802, 20837, 20867, 20911, 20930, 20939, 20970, 20981, 21022, 21088, 21114, 21174, 21175, 21215, 21221, 21293, 21332, 21386, 21391, 21398, 21484, 21549, 21559, 21567, 21579, 21592, 21610, 21619, 21628, 21665, 21716, 21788, 21790, 21800, 21831, 22035, 22096, 22178, 22205, 22349, 22374, 22377, 22386, 22397, 22406, 22485, 22487, 22545, 22577, 22578, 22579, 22626, 22635, 22678, 22691, 22707, 22714, 22747, 22758, 22763, 22764, 22788, 22798, 22818, 22843, 22849, 22888, 22921, 22952, 22993, 23000, 23020, 23039, 23050, 23098, 23106, 23157, 23165, 23220, 23292, 23294, 23346, 23401, 23407, 23434, 23474, 23492, 23521, 23582, 23698, 23727, 23764, 23789, 23823, 23854, 23882, 23935, 23943, 23991, 24001, 24021, 24068, 24074, 24104, 24145, 24210, 24320, 24435, 24439, 24471, 24486, 24490, 24494, 24506, 24515, 24520, 24536, 24538, 24573, 24575, 24597, 24670, 24688, 24703, 24786, 24802, 24823, 24842, 24848, 24869, 24887, 24963, 25018, 25022, 25044, 25049, 25053, 25118, 25175, 25177, 25185, 25195, 25208, 25214, 25251, 25262, 25283, 25305, 25335, 25348, 25351, 25353, 25355, 25361, 25397, 25403, 25404, 25411, 25430, 25437, 25461, 25472, 25505, 25558, 25561, 25579, 25587, 25600, 25605, 25643, 25654, 25656, 25664, 25674, 25714, 25765, 25828, 25919, 26024, 26045, 26074, 26077, 26117, 26123, 26124, 26150, 26161, 26178, 26185, 26355, 26362, 26379, 26393, 26429, 26444, 26459, 26472, 26529, 26580, 26588, 26607, 26681, 26738, 26755, 26785, 26815, 26843, 26858, 26864, 26884, 26915, 26919, 27030, 27043, 27062, 27063, 27089, 27100, 27103, 27120, 27183, 27189, 27195, 27206, 27217, 27267, 27284, 27382, 27420, 27428, 27454, 27464, 27483, 27485, 27554, 27557, 27587, 27625, 27630, 27632, 27642, 27662, 27678, 27713, 27797, 27815, 27853, 27873, 27879, 27893, 27895, 27896, 27911, 27930, 27936, 27996, 28013, 28032, 28046, 28059, 28080, 28093, 28098, 28103, 28104, 28110, 28140, 28226, 28243, 28248, 28283, 28292, 28325, 28330, 28344, 28358, 28397, 28416, 28418, 28451, 28479, 28531, 28545, 28577, 28581, 28610, 28681, 28691, 28742, 28765, 28782, 28793, 28805, 28819, 28830, 28902, 28954, 28968, 29064, 29078, 29092, 29109, 29110, 29114, 29126, 29229, 29322, 29356, 29370, 29435, 29454, 29470, 29528, 29537, 29573, 29590, 29595, 29604, 29616, 29668, 29675, 29713, 29753, 29837, 29851, 29863, 29916, 29946, 29953, 30002, 30043, 30075, 30157, 30176, 30202, 30209, 30217, 30269, 30285, 30286, 30407, 30408, 30424, 30508, 30516, 30530, 30536, 30548, 30625, 30628, 30832, 30918, 30972, 30985, 31011, 31032, 31040, 31057, 31114, 31119, 31131, 31189, 31221, 31239, 31240, 31242, 31246, 31270, 31286, 31300, 31332, 31336, 31347, 31375, 31399, 31408, 31470, 31530, 31541, 31553, 31557, 31575, 31581, 31600, 31676, 31755, 31797, 31803, 31862, 31870, 31919, 31945, 31957, 31988, 31994, 32012, 32042, 32049, 32103, 32128, 32225, 32228, 32240, 32253, 32262, 32284, 32294, 32310, 32332, 32348, 32360, 32396, 32413, 32416, 32436, 32445, 32491, 32505, 32511, 32533, 32538, 32570, 32573, 32577, 32579, 32590, 32597, 32623, 32677, 32702, 32723, 32727, 32737, 32808, 32839, 32849, 32857, 32873, 32876, 32946, 32958, 32967, 33035, 33111, 33149, 33161, 33185, 33202, 33211, 33251, 33259, 33320, 33362, 33386, 33394, 33457, 33494, 33498, 33529, 33599, 33625, 33652, 33688, 33708, 33895, 33924, 34019, 34057, 34092, 34107, 34116, 34137, 34139, 34157, 34164, 34200, 34214, 34219, 34224, 34227, 34232, 34286, 34359, 34423, 34427, 34450, 34522, 34535, 34564, 34567, 34668, 34688, 34725, 34744, 34756, 34769, 34846, 34956, 35017, 35030, 35050, 35060, 35117, 35119, 35146, 35172, 35229, 35240, 35332, 35373, 35375, 35393, 35445, 35449, 35454, 35491, 35493, 35512, 35514, 35520, 35535, 35542, 35544, 35585, 35605, 35608, 35677, 35689, 35699, 35715, 35727, 35729, 35731, 35743, 35767, 35768, 35777], Count: 1278\n",
      "Outliers in column 'opponent_rank': [25, 31, 35, 50, 61, 85, 131, 133, 154, 180, 206, 275, 277, 310, 322, 340, 369, 389, 504, 520, 531, 551, 554, 574, 577, 588, 593, 596, 668, 685, 705, 800, 862, 893, 903, 924, 927, 948, 958, 961, 964, 994, 1060, 1081, 1092, 1110, 1129, 1133, 1224, 1247, 1271, 1327, 1333, 1344, 1350, 1369, 1393, 1451, 1461, 1524, 1537, 1583, 1586, 1613, 1620, 1633, 1645, 1648, 1661, 1683, 1687, 1714, 1812, 1816, 1859, 1896, 1912, 1937, 1939, 1979, 1997, 2008, 2010, 2032, 2040, 2047, 2069, 2174, 2195, 2314, 2344, 2456, 2477, 2517, 2549, 2573, 2615, 2619, 2639, 2649, 2697, 2729, 2733, 2748, 2756, 2826, 2841, 2863, 2933, 2972, 2975, 3075, 3090, 3125, 3154, 3181, 3198, 3208, 3264, 3282, 3346, 3364, 3367, 3386, 3393, 3406, 3471, 3485, 3512, 3521, 3537, 3617, 3635, 3648, 3653, 3665, 3690, 3712, 3722, 3804, 3864, 3880, 3897, 3911, 3934, 3936, 3993, 4029, 4031, 4047, 4053, 4076, 4099, 4127, 4168, 4191, 4241, 4278, 4308, 4337, 4368, 4375, 4506, 4522, 4547, 4593, 4612, 4645, 4648, 4668, 4679, 4682, 4703, 4717, 4725, 4784, 4822, 4825, 4840, 4851, 4855, 4910, 4934, 4942, 4974, 4976, 5013, 5030, 5036, 5037, 5067, 5070, 5124, 5137, 5148, 5157, 5158, 5174, 5180, 5250, 5299, 5329, 5353, 5502, 5533, 5534, 5561, 5563, 5576, 5579, 5580, 5587, 5595, 5608, 5672, 5691, 5777, 5793, 5799, 5818, 5878, 5884, 5888, 5937, 5941, 5946, 5958, 6043, 6046, 6086, 6088, 6089, 6096, 6147, 6204, 6207, 6219, 6236, 6251, 6271, 6289, 6310, 6311, 6370, 6406, 6409, 6455, 6464, 6476, 6479, 6480, 6517, 6522, 6534, 6551, 6571, 6596, 6606, 6637, 6648, 6663, 6701, 6715, 6736, 6758, 6853, 6902, 6904, 6911, 6913, 6952, 6958, 6970, 6989, 6999, 7016, 7040, 7042, 7062, 7096, 7124, 7209, 7219, 7227, 7274, 7278, 7283, 7309, 7335, 7347, 7416, 7431, 7474, 7480, 7489, 7507, 7526, 7535, 7566, 7577, 7582, 7607, 7643, 7646, 7684, 7817, 7836, 7840, 7851, 7856, 7888, 7901, 7916, 7926, 7987, 7992, 8025, 8027, 8035, 8061, 8110, 8128, 8135, 8196, 8259, 8281, 8295, 8317, 8330, 8350, 8406, 8426, 8442, 8448, 8457, 8471, 8514, 8605, 8667, 8733, 8750, 8760, 8778, 8819, 8829, 8843, 8858, 8863, 8878, 8894, 8902, 8926, 8933, 9018, 9052, 9180, 9252, 9287, 9293, 9299, 9370, 9375, 9380, 9436, 9501, 9525, 9546, 9623, 9656, 9663, 9672, 9676, 9687, 9690, 9698, 9731, 9760, 9796, 9861, 9874, 9898, 9918, 9922, 9945, 9957, 9966, 9990, 10002, 10019, 10026, 10052, 10079, 10115, 10118, 10121, 10141, 10162, 10173, 10182, 10226, 10261, 10268, 10367, 10439, 10456, 10462, 10471, 10507, 10532, 10570, 10579, 10580, 10627, 10638, 10648, 10663, 10699, 10806, 10885, 10899, 10913, 10919, 10958, 10960, 10988, 11024, 11049, 11174, 11219, 11223, 11234, 11253, 11266, 11270, 11342, 11377, 11430, 11451, 11473, 11480, 11486, 11509, 11537, 11565, 11575, 11589, 11593, 11611, 11686, 11703, 11706, 11712, 11810, 11850, 11862, 11870, 11891, 11947, 11955, 11960, 11976, 11985, 12000, 12030, 12046, 12060, 12086, 12089, 12094, 12108, 12171, 12180, 12212, 12251, 12307, 12322, 12370, 12394, 12433, 12443, 12455, 12510, 12524, 12591, 12603, 12606, 12635, 12640, 12642, 12645, 12677, 12743, 12761, 12772, 12785, 12828, 12834, 12882, 12893, 12940, 12972, 13007, 13009, 13032, 13037, 13044, 13054, 13123, 13124, 13131, 13138, 13153, 13181, 13186, 13198, 13209, 13211, 13219, 13236, 13247, 13285, 13300, 13311, 13386, 13391, 13416, 13419, 13431, 13433, 13511, 13545, 13546, 13550, 13587, 13606, 13620, 13637, 13658, 13673, 13676, 13684, 13691, 13718, 13724, 13731, 13756, 13775, 13778, 13808, 13841, 13856, 13868, 13918, 13943, 13977, 13994, 14010, 14021, 14053, 14088, 14093, 14105, 14123, 14160, 14211, 14214, 14216, 14247, 14256, 14304, 14305, 14311, 14314, 14334, 14374, 14382, 14386, 14392, 14406, 14410, 14485, 14524, 14526, 14531, 14618, 14683, 14695, 14702, 14712, 14732, 14758, 14770, 14772, 14782, 14791, 14798, 14805, 14896, 14898, 14914, 15028, 15130, 15185, 15213, 15240, 15273, 15316, 15345, 15365, 15370, 15375, 15401, 15444, 15447, 15526, 15565, 15578, 15585, 15609, 15619, 15642, 15647, 15650, 15662, 15707, 15807, 15840, 15908, 15953, 15982, 15993, 15996, 16018, 16031, 16067, 16123, 16128, 16141, 16144, 16188, 16216, 16239, 16299, 16313, 16341, 16369, 16370, 16418, 16433, 16447, 16481, 16494, 16515, 16552, 16612, 16656, 16657, 16709, 16736, 16827, 16867, 16881, 16923, 16946, 16995, 17006, 17011, 17021, 17105, 17119, 17146, 17152, 17229, 17233, 17234, 17242, 17312, 17335, 17440, 17466, 17468, 17492, 17505, 17506, 17531, 17532, 17535, 17540, 17552, 17587, 17669, 17681, 17704, 17716, 17728, 17755, 17761, 17764, 17779, 17781, 17815, 17817, 17905, 17906, 17941, 17976, 17983, 17997, 18003, 18036, 18102, 18138, 18147, 18194, 18212, 18220, 18236, 18239, 18249, 18269, 18332, 18370, 18406, 18454, 18466, 18514, 18518, 18522, 18586, 18648, 18655, 18672, 18693, 18701, 18728, 18803, 18814, 18823, 18885, 18910, 18935, 18941, 18953, 18982, 19010, 19076, 19095, 19109, 19129, 19152, 19174, 19176, 19202, 19309, 19335, 19355, 19376, 19454, 19505, 19541, 19548, 19575, 19610, 19614, 19617, 19651, 19657, 19688, 19715, 19731, 19771, 19811, 19877, 19894, 19911, 19941, 19962, 19964, 20051, 20062, 20081, 20084, 20097, 20188, 20191, 20208, 20258, 20279, 20291, 20331, 20334, 20343, 20353, 20354, 20370, 20403, 20411, 20436, 20471, 20479, 20483, 20512, 20528, 20603, 20673, 20704, 20712, 20759, 20808, 20824, 20829, 20839, 20930, 21069, 21114, 21180, 21198, 21258, 21340, 21341, 21433, 21437, 21494, 21540, 21541, 21553, 21557, 21559, 21618, 21620, 21665, 21716, 21766, 21778, 21798, 21881, 21913, 21929, 21940, 21983, 22078, 22100, 22112, 22144, 22151, 22178, 22182, 22223, 22237, 22285, 22305, 22415, 22429, 22436, 22471, 22492, 22499, 22507, 22508, 22545, 22606, 22617, 22635, 22690, 22788, 22797, 22921, 22925, 22941, 22949, 22958, 22982, 23000, 23020, 23050, 23057, 23098, 23161, 23165, 23175, 23180, 23208, 23209, 23215, 23269, 23323, 23328, 23331, 23373, 23376, 23434, 23454, 23474, 23505, 23529, 23550, 23590, 23630, 23665, 23695, 23698, 23709, 23714, 23716, 23728, 23748, 23764, 23811, 23829, 23840, 23846, 23872, 23883, 23946, 23949, 23991, 23994, 23998, 24064, 24126, 24145, 24211, 24216, 24261, 24262, 24300, 24320, 24329, 24360, 24393, 24435, 24454, 24471, 24497, 24499, 24538, 24583, 24594, 24690, 24723, 24731, 24733, 24737, 24743, 24783, 24810, 24847, 24863, 24930, 24982, 24983, 25029, 25030, 25101, 25137, 25147, 25160, 25162, 25208, 25230, 25262, 25320, 25333, 25335, 25355, 25403, 25404, 25411, 25464, 25485, 25505, 25648, 25664, 25680, 25714, 25715, 25790, 25806, 25853, 25913, 25919, 25998, 26037, 26057, 26074, 26091, 26117, 26124, 26161, 26177, 26183, 26192, 26240, 26343, 26379, 26388, 26394, 26438, 26477, 26479, 26607, 26633, 26639, 26692, 26736, 26753, 26790, 26797, 26842, 26858, 26911, 26929, 26993, 27007, 27011, 27012, 27019, 27029, 27043, 27064, 27080, 27118, 27174, 27183, 27232, 27274, 27280, 27353, 27397, 27438, 27452, 27483, 27485, 27523, 27524, 27547, 27625, 27647, 27678, 27725, 27746, 27796, 27834, 27838, 27870, 27871, 27888, 28013, 28181, 28248, 28290, 28307, 28446, 28453, 28565, 28604, 28727, 28765, 28773, 28777, 28791, 28878, 28889, 28902, 28920, 28937, 28989, 29046, 29084, 29106, 29115, 29126, 29320, 29348, 29350, 29375, 29435, 29437, 29446, 29473, 29508, 29522, 29528, 29534, 29625, 29642, 29653, 29677, 29683, 29695, 29746, 29772, 29808, 29870, 29882, 29932, 29990, 30002, 30043, 30044, 30115, 30176, 30263, 30264, 30292, 30293, 30299, 30321, 30367, 30413, 30416, 30446, 30499, 30508, 30519, 30564, 30570, 30575, 30579, 30581, 30587, 30668, 30679, 30685, 30771, 30789, 30832, 30835, 30838, 30894, 30952, 30999, 31032, 31189, 31203, 31214, 31221, 31239, 31242, 31264, 31300, 31340, 31351, 31371, 31381, 31399, 31433, 31491, 31515, 31557, 31584, 31590, 31686, 31716, 31731, 31734, 31746, 31794, 31797, 31803, 31820, 31852, 31862, 31869, 31897, 31919, 31988, 31998, 32003, 32049, 32134, 32149, 32155, 32200, 32225, 32247, 32287, 32289, 32294, 32332, 32336, 32348, 32419, 32505, 32532, 32547, 32597, 32623, 32653, 32723, 32778, 32827, 32857, 32934, 33019, 33049, 33054, 33070, 33117, 33180, 33202, 33235, 33299, 33309, 33362, 33385, 33394, 33397, 33407, 33415, 33437, 33459, 33529, 33568, 33593, 33613, 33640, 33652, 33706, 33761, 33777, 33827, 33898, 33904, 33912, 33934, 33952, 34020, 34059, 34088, 34107, 34197, 34204, 34207, 34219, 34241, 34276, 34311, 34343, 34406, 34442, 34485, 34535, 34555, 34641, 34747, 34854, 34878, 34896, 35050, 35101, 35113, 35120, 35166, 35175, 35181, 35200, 35229, 35236, 35237, 35240, 35242, 35261, 35286, 35307, 35361, 35373, 35442, 35445, 35493, 35520, 35522, 35525, 35582, 35648, 35698, 35707, 35751], Count: 1278\n"
     ]
    }
   ],
   "source": [
    "df_outlier1 = df_home.copy()\n",
    "def detect_outliers(df, column, threshold=4):\n",
    "    \"\"\"\n",
    "    Detect outliers in a dataframe column using the IQR method.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the indices of the outliers.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)].index.tolist()\n",
    "    return outliers\n",
    "\n",
    "\n",
    "numeric_columns = ['player_ht', 'player_age', 'opponent_ht', 'opponent_age', 'player_rank', 'opponent_rank']\n",
    "outliers = {}\n",
    "outliers_count={}\n",
    "for column in numeric_columns:\n",
    "    outliers[column] = detect_outliers(df_outlier1, column)\n",
    "    outliers_count[column] = len(outliers[column])\n",
    "\n",
    "\n",
    "# Print out indices of outliers for each column\n",
    "for column, indices in outliers.items():\n",
    "    print(f\"Outliers in column '{column}': {indices}, Count: {outliers_count[column]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>player</th>\n",
       "      <th>opponent</th>\n",
       "      <th>player_hand</th>\n",
       "      <th>player_ht</th>\n",
       "      <th>player_age</th>\n",
       "      <th>opponent_hand</th>\n",
       "      <th>opponent_ht</th>\n",
       "      <th>opponent_age</th>\n",
       "      <th>win</th>\n",
       "      <th>player_rank</th>\n",
       "      <th>opponent_rank</th>\n",
       "      <th>is_player_home_country</th>\n",
       "      <th>is_opponent_home_country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Johnson S.</td>\n",
       "      <td>Harris L.</td>\n",
       "      <td>R</td>\n",
       "      <td>188.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>R</td>\n",
       "      <td>193.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Round of 128</td>\n",
       "      <td>Melzer G.</td>\n",
       "      <td>Monteiro T.</td>\n",
       "      <td>L</td>\n",
       "      <td>188.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>L</td>\n",
       "      <td>183.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Round of 32</td>\n",
       "      <td>Benneteau J.</td>\n",
       "      <td>Fognini F.</td>\n",
       "      <td>R</td>\n",
       "      <td>185.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>R</td>\n",
       "      <td>178.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Querrey S.</td>\n",
       "      <td>Young D.</td>\n",
       "      <td>R</td>\n",
       "      <td>198.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>L</td>\n",
       "      <td>183.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semifinals</td>\n",
       "      <td>Dzumhur D.</td>\n",
       "      <td>Basic M.</td>\n",
       "      <td>R</td>\n",
       "      <td>172.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>R</td>\n",
       "      <td>188.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35829</th>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Ramos-Vinolas A.</td>\n",
       "      <td>Cecchinato M.</td>\n",
       "      <td>L</td>\n",
       "      <td>188.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>R</td>\n",
       "      <td>185.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35830</th>\n",
       "      <td>Round of 32</td>\n",
       "      <td>Novak D.</td>\n",
       "      <td>Darcis S.</td>\n",
       "      <td>R</td>\n",
       "      <td>183.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>R</td>\n",
       "      <td>178.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35831</th>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Daniel T.</td>\n",
       "      <td>Nadal R.</td>\n",
       "      <td>R</td>\n",
       "      <td>191.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>L</td>\n",
       "      <td>185.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35832</th>\n",
       "      <td>Round of 128</td>\n",
       "      <td>Kukushkin M.</td>\n",
       "      <td>Klizan M.</td>\n",
       "      <td>R</td>\n",
       "      <td>183.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>L</td>\n",
       "      <td>190.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35833</th>\n",
       "      <td>Round of 64</td>\n",
       "      <td>Benneteau J.</td>\n",
       "      <td>Ferrer D.</td>\n",
       "      <td>R</td>\n",
       "      <td>185.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>R</td>\n",
       "      <td>175.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33724 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Round            player       opponent player_hand  player_ht  \\\n",
       "0       Round of 16        Johnson S.      Harris L.           R      188.0   \n",
       "1      Round of 128         Melzer G.    Monteiro T.           L      188.0   \n",
       "2       Round of 32      Benneteau J.     Fognini F.           R      185.0   \n",
       "3       Round of 64        Querrey S.       Young D.           R      198.0   \n",
       "4        Semifinals        Dzumhur D.       Basic M.           R      172.0   \n",
       "...             ...               ...            ...         ...        ...   \n",
       "35829   Round of 64  Ramos-Vinolas A.  Cecchinato M.           L      188.0   \n",
       "35830   Round of 32          Novak D.      Darcis S.           R      183.0   \n",
       "35831   Round of 64         Daniel T.       Nadal R.           R      191.0   \n",
       "35832  Round of 128      Kukushkin M.      Klizan M.           R      183.0   \n",
       "35833   Round of 64      Benneteau J.      Ferrer D.           R      185.0   \n",
       "\n",
       "       player_age opponent_hand  opponent_ht  opponent_age  win  player_rank  \\\n",
       "0            30.8             R        193.0          23.6    0         25.0   \n",
       "1            34.0             L        183.0          24.7    0         68.0   \n",
       "2            43.0             R        178.0          31.6    0         55.0   \n",
       "3            31.2             L        183.0          35.0    0         11.0   \n",
       "4            26.7             R        188.0          27.5    1         23.0   \n",
       "...           ...           ...          ...           ...  ...          ...   \n",
       "35829        36.0             R        185.0          26.2    1         17.0   \n",
       "35830        25.8             R        178.0          35.3    1         85.0   \n",
       "35831        25.9             L        185.0          32.6    0         69.0   \n",
       "35832        31.4             L        190.0          29.8    0         40.0   \n",
       "35833        43.0             R        175.0          42.0    1         55.0   \n",
       "\n",
       "       opponent_rank  is_player_home_country  is_opponent_home_country  year  \\\n",
       "0               72.0                   False                     False  2020   \n",
       "1               74.0                   False                     False  2018   \n",
       "2                9.0                   False                     False  2018   \n",
       "3               42.0                   False                     False  2017   \n",
       "4               75.0                   False                     False  2017   \n",
       "...              ...                     ...                       ...   ...   \n",
       "35829           16.0                   False                     False  2019   \n",
       "35830           38.0                   False                     False  2019   \n",
       "35831            1.0                   False                     False  2017   \n",
       "35832           34.0                   False                     False  2019   \n",
       "35833           21.0                   False                     False  2016   \n",
       "\n",
       "       month  day  dayofweek  \n",
       "0         10   12          0  \n",
       "1          5    1          1  \n",
       "2          1   20          5  \n",
       "3          3   12          6  \n",
       "4         10   21          5  \n",
       "...      ...  ...        ...  \n",
       "35829      3    9          5  \n",
       "35830      7   15          0  \n",
       "35831      9    1          4  \n",
       "35832      5   27          0  \n",
       "35833      1    1          4  \n",
       "\n",
       "[33724 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "df_outlier2 = df_home.copy()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df_outlier2[numeric_columns]))\n",
    "filtered_entries = (z_scores < 3).all(axis=1)\n",
    "df_outlier2 = df_outlier2[filtered_entries]\n",
    "df_outlier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the date using sin and cos to preserve the cyclical nature of\n",
    "def encode_date(df):\n",
    "    df_date_encoded = df.copy()\n",
    "    df_date_encoded['month_sin'] = np.sin(2 * np.pi * df_date_encoded['month']/12)\n",
    "    df_date_encoded['month_cos'] = np.cos(2 * np.pi * df_date_encoded['month']/12)\n",
    "    df_date_encoded['dayofweek_sin'] = np.sin(2 * np.pi * df_date_encoded['dayofweek']/7)\n",
    "    df_date_encoded['dayofweek_cos'] = np.cos(2 * np.pi * df_date_encoded['dayofweek']/7)\n",
    "    df_date_encoded['day_sin'] = np.sin(2 * np.pi * df_date_encoded['day']/30.5)\n",
    "    df_date_encoded['day_cos'] = np.cos(2 * np.pi * df_date_encoded['day']/30.5)\n",
    "    df_date_encoded.drop(columns=[\"month\",\"dayofweek\", \"day\"], inplace=True)\n",
    "    return df_date_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding rounds, no need to scale because the higher the round is, the more important it is\n",
    "def encode_round(df):\n",
    "    df_round_encoded = df.copy()\n",
    "    round_mapping = {\n",
    "        '1st Round Qualifying': 1,\n",
    "        '2nd Round Qualifying': 2,\n",
    "        '3rd Round Qualifying': 3,\n",
    "        'Round Robin': 4,\n",
    "        'Round of 128': 5,\n",
    "        'Round of 64': 6,\n",
    "        'Round of 32': 7,\n",
    "        'Round of 16': 8,\n",
    "        'Quarterfinals': 9,\n",
    "        'Semifinals': 10,\n",
    "        'The Final': 11\n",
    "    }\n",
    "    df_round_encoded['Round'] = df_round_encoded['Round'].map(round_mapping)\n",
    "    return df_round_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary encoding for columns in columnNames = ['is_player_home_country','is_opponent_home_country',\"is_taller\", \"is_older\", \"rank_is_higher\"]\n",
    "def binary_column(df):\n",
    "    df_binary = df.copy()\n",
    "    df_binary['is_older'] = df_binary['player_age'] > df_binary['opponent_age']\n",
    "    df_binary['is_taller'] = df_binary['player_ht'] > df_binary['opponent_ht']\n",
    "    df_binary['rank_is_higher'] = df_binary['player_rank'] > df_binary['opponent_rank']\n",
    "\n",
    "    df_binary.drop(columns=[\"player_age\",'opponent_age', 'player_ht',\"opponent_ht\",'player_rank', 'opponent_rank'], inplace=True)\n",
    "    return df_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integer encoding for handedness\n",
    "def int_encode_hand(df):\n",
    "    df_hand_int_encoded = df.copy()\n",
    "    hand_mapping = {\n",
    "        'R': 1,\n",
    "        'L': 2,\n",
    "        'U': 0\n",
    "    }\n",
    "    df_hand_int_encoded['player_hand'] = df_hand_int_encoded['player_hand'].map(hand_mapping)\n",
    "    df_hand_int_encoded['opponent_hand'] = df_hand_int_encoded['opponent_hand'].map(hand_mapping)\n",
    "    return df_hand_int_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding for handedness\n",
    "def hot_encode_hand(df):\n",
    "    df_hand_1hot_encoded = df.copy()\n",
    "\n",
    "    df_hand_1hot_encoded = pd.get_dummies(df_hand_1hot_encoded, columns=['player_hand'], prefix='player_hand')\n",
    "    df_hand_1hot_encoded = pd.get_dummies(df_hand_1hot_encoded, columns=['opponent_hand'], prefix='opponent_hand')\n",
    "    return df_hand_1hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pipeline_L1(df):\n",
    "    df1 = df.copy()\n",
    "    df2 = encode_date(df1)\n",
    "    df3 = encode_round(df2)\n",
    "    df_int_hand = int_encode_hand(df3)\n",
    "    df_hot_hand = hot_encode_hand(df3)\n",
    "    return df_int_hand,df_hot_hand,binary_column(df_int_hand),binary_column(df_hot_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize function\n",
    "numeric_columns_1 = ['player_ht', 'opponent_ht']\n",
    "numeric_columns_2 = ['player_age','opponent_age']\n",
    "numeric_columns_3 = ['player_rank', 'opponent_rank']\n",
    "numeric_columns_4 = [\"year\"]\n",
    "\n",
    "def normalize(og_df, numeric_columns):\n",
    "    df = og_df.copy()\n",
    "    for column in numeric_columns:\n",
    "        # Z-score normalization\n",
    "        df[f'{column}_zscore'] = (df[column] - df[column].mean()) / df[column].std()\n",
    "        # Min-max scaling\n",
    "        df[f'{column}_minmax'] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "        # Decimal scaling\n",
    "        max_length = max(df[column].apply(lambda x: len(str(np.floor(x))) if x > 0 else 1))\n",
    "        df[f'{column}_decimal'] = df[column] / (10**max_length)\n",
    "    df.drop(columns=numeric_columns, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no normalization (NN) has home\n",
    "df_hand_int_encoded_home, df_hand_1hot_encoded_home, df_hand_int_encoded_bool, df_hand_1hot_encoded_bool = encode_pipeline_L1(df_home)\n",
    "\n",
    "#normalize all\n",
    "enc_int_N_Outlier_filled_dropped_nulls = normalize(df_hand_int_encoded_home,numeric_columns_1+numeric_columns_2+numeric_columns_3+numeric_columns_4)\n",
    "enc_1hot_N_Outlier_filled_dropped_nulls = normalize(df_hand_1hot_encoded_home,numeric_columns_1+numeric_columns_2+numeric_columns_3+numeric_columns_4)\n",
    "\n",
    "#normalize year\n",
    "enc_int_Nyear_Outlier_filled_dropped_nulls_bool = normalize(df_hand_int_encoded_bool,numeric_columns_4)\n",
    "enc_1hot_Nyear_Outlier_filled_dropped_nulls_bool = normalize(df_hand_1hot_encoded_bool,numeric_columns_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df without outlier\n",
    "df_hand_int_encoded_outlier, df_hand_1hot_encoded_outlier,df_hand_int_encoded_bool_outlier,df_hand_1hot_encoded_bool_outlier = encode_pipeline_L1(df_outlier2)\n",
    "\n",
    "#normalize all\n",
    "enc_int_N_noOutlier_filled_dropped_nulls = normalize(df_hand_int_encoded_outlier,numeric_columns_1+numeric_columns_2+numeric_columns_3+numeric_columns_4)\n",
    "enc_1hot_N_noOutlier_filled_dropped_nulls = normalize(df_hand_1hot_encoded_outlier,numeric_columns_1+numeric_columns_2+numeric_columns_3+numeric_columns_4)\n",
    "\n",
    "#normalize year\n",
    "enc_int_Nyear_noOutlier_filled_dropped_nulls_bool = normalize(df_hand_int_encoded_bool_outlier,numeric_columns_4)\n",
    "enc_1hot_Nyear_noOutlier_filled_dropped_nulls_bool = normalize(df_hand_1hot_encoded_bool_outlier,numeric_columns_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df without nulls\n",
    "df_no_nulls = df_drop_nulls.copy()\n",
    "\n",
    "df_hand_int_encoded_nnull, df_hand_1hot_encoded_nnull,df_hand_int_encoded_bool_nnull,df_hand_1hot_encoded_bool_nnull = encode_pipeline_L1(df_no_nulls)\n",
    "\n",
    "#normalize all\n",
    "enc_int_N_Outlier_dropped_nulls = normalize(df_hand_int_encoded_nnull,numeric_columns_1+numeric_columns_2+numeric_columns_3+numeric_columns_4)\n",
    "enc_1hot_N_Outlier_dropped_nulls = normalize(df_hand_1hot_encoded_nnull,numeric_columns_1+numeric_columns_2+numeric_columns_3+numeric_columns_4)\n",
    "\n",
    "#normalize year\n",
    "enc_int_Nyear_Outlier_dropped_nulls_bool = normalize(df_hand_int_encoded_bool_nnull,numeric_columns_4)\n",
    "enc_1hot_Nyear_Outlier_dropped_nulls_bool = normalize(df_hand_1hot_encoded_bool_nnull,numeric_columns_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "#split df into training and testing\n",
    "def split_df(df):\n",
    "    working_df = df.copy()\n",
    "    X = working_df.drop(['win', 'player', 'opponent'], axis=1)  # Exclude non-numeric or target columns\n",
    "    y = working_df['win']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#train Linear SVC model\n",
    "def lin_svc_model(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the SVM classifier\n",
    "    lsvm_model = LinearSVC(dual=True, max_iter=10000, random_state=1)\n",
    "    lsvm_model.fit(X_train, y_train)\n",
    "    y_pred_lsvm = lsvm_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_lsvm))\n",
    "    return y_test, y_pred_lsvm\n",
    "\n",
    "#train SVC model\n",
    "def svc_model(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the SVM classifier\n",
    "    svm_model = SVC(kernel='linear', probability=True, random_state=1)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_svm))\n",
    "    return y_test, y_pred_svm, svm_model, X_test\n",
    "\n",
    "#train random forest model\n",
    "def rfc_model(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "    return y_test, y_pred_rf, rf_model, X_test\n",
    "\n",
    "#train logistic regression model\n",
    "def logReg_model(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the Logistic Regression classifier\n",
    "    lr_model = LogisticRegression(random_state=1)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    y_pred_lr = lr_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_lr))\n",
    "    return y_test, y_pred_lr, lr_model, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split df into training and testing\n",
    "def split_df(df):\n",
    "    working_df = df.copy()\n",
    "    X = working_df.drop(['win', 'player', 'opponent'], axis=1)  # Exclude non-numeric or target columns\n",
    "    y = working_df['win']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#train random forest model\n",
    "def rfc_model(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    return y_test, y_pred_rf, rf_model, X_test\n",
    "\n",
    "def calcMetrics(y_test, y_pred, model, X_test):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])  # For binary classifications\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "def rfc_pipeline(og_df):\n",
    "    print(\"Random Forest Classifier\")\n",
    "    df = og_df.copy()\n",
    "    X_train, X_test, y_train, y_test = split_df(df)\n",
    "    y_test, y_pred, model, X_test = rfc_model(X_train, X_test, y_train, y_test)\n",
    "    calcMetrics(y_test, y_pred, model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def calcMetric(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "def calcMetrics(y_test, y_pred, model, X_test):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])  # For binary classifications\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_svc_pipeline(og_df):\n",
    "    print(\"Linear Support Vector Classifier\")\n",
    "    df = og_df.copy()\n",
    "    X_train, X_test, y_train, y_test = split_df(df)\n",
    "    y_test, y_pred= lin_svc_model(X_train, X_test, y_train, y_test)\n",
    "    calcMetric(y_test, y_pred)\n",
    "\n",
    "def svc_pipeline(og_df):\n",
    "    print(\"Support Vector Classifier\")\n",
    "    df = og_df.copy()\n",
    "    X_train, X_test, y_train, y_test = split_df(df)\n",
    "    y_test, y_pred, model, X_test = svc_model(X_train, X_test, y_train, y_test)\n",
    "    calcMetrics(y_test, y_pred, model, X_test)\n",
    "\n",
    "def rfc_pipeline(og_df):\n",
    "    print(\"Random Forest Classifier\")\n",
    "    df = og_df.copy()\n",
    "    X_train, X_test, y_train, y_test = split_df(df)\n",
    "    y_test, y_pred, model, X_test = rfc_model(X_train, X_test, y_train, y_test)\n",
    "    calcMetrics(y_test, y_pred, model, X_test)\n",
    "    \n",
    "def logReg_pipeline(og_df):\n",
    "    print(\"Logistic regression Classifier\")\n",
    "    df = og_df.copy()\n",
    "    X_train, X_test, y_train, y_test = split_df(df)\n",
    "    y_test, y_pred, model, X_test = logReg_model(X_train, X_test, y_train, y_test)\n",
    "    calcMetrics(y_test, y_pred, model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Round', 'player', 'opponent', 'player_hand', 'opponent_hand', 'win',\n",
       "       'is_player_home_country', 'is_opponent_home_country', 'month_sin',\n",
       "       'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'day_sin', 'day_cos',\n",
       "       'player_ht_zscore', 'player_ht_minmax', 'player_ht_decimal',\n",
       "       'opponent_ht_zscore', 'opponent_ht_minmax', 'opponent_ht_decimal',\n",
       "       'player_age_zscore', 'player_age_minmax', 'player_age_decimal',\n",
       "       'opponent_age_zscore', 'opponent_age_minmax', 'opponent_age_decimal',\n",
       "       'player_rank_zscore', 'player_rank_minmax', 'player_rank_decimal',\n",
       "       'opponent_rank_zscore', 'opponent_rank_minmax', 'opponent_rank_decimal',\n",
       "       'year_zscore', 'year_minmax', 'year_decimal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframes = [df_hand_int_encoded_NN,df_hand_1hot_encoded_NN,df_hand_int_N_all,df_hand_1hot_N_all]\n",
    "# dataframe_names = [\"hand_int_encoded_NN\",\"hand_1hot_encoded_NN\",\"hand_int_N_all\",\"hand_1hot_N_all\"]\n",
    "\n",
    "dataframes = [enc_int_N_Outlier_filled_dropped_nulls,enc_1hot_N_Outlier_filled_dropped_nulls,enc_int_Nyear_Outlier_filled_dropped_nulls_bool,enc_1hot_Nyear_Outlier_filled_dropped_nulls_bool,\n",
    "              enc_int_N_noOutlier_filled_dropped_nulls,enc_1hot_N_noOutlier_filled_dropped_nulls,enc_int_Nyear_noOutlier_filled_dropped_nulls_bool,enc_1hot_Nyear_noOutlier_filled_dropped_nulls_bool,\n",
    "              enc_int_N_Outlier_dropped_nulls,enc_1hot_N_Outlier_dropped_nulls,enc_int_Nyear_Outlier_dropped_nulls_bool,enc_1hot_Nyear_Outlier_dropped_nulls_bool]\n",
    "dataframe_names = [\"enc_int_N_Outlier_filled_dropped_nulls\",\"enc_1hot_N_Outlier_filled_dropped_nulls\",\"enc_int_Nyear_Outlier_filled_dropped_nulls_bool\",\"enc_1hot_Nyear_Outlier_filled_dropped_nulls_bool\",\n",
    "              \"enc_int_N_noOutlier_filled_dropped_nulls\",\"enc_1hot_N_noOutlier_filled_dropped_nulls\",\"enc_int_Nyear_noOutlier_filled_dropped_nulls_bool\",\"enc_1hot_Nyear_noOutlier_filled_dropped_nulls_bool\",\n",
    "              \"enc_int_N_Outlier_dropped_nulls\",\"enc_1hot_N_Outlier_dropped_nulls\",\"enc_int_Nyear_Outlier_dropped_nulls_bool\",\"enc_1hot_Nyear_Outlier_dropped_nulls_bool\"]\n",
    "enc_int_N_Outlier_filled_dropped_nulls.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      4071\n",
      "           1       0.76      0.77      0.77      3898\n",
      "\n",
      "    accuracy                           0.77      7969\n",
      "   macro avg       0.77      0.77      0.77      7969\n",
      "weighted avg       0.77      0.77      0.77      7969\n",
      "\n",
      "Accuracy: 0.7703601455640607\n",
      "Precision: 0.7628368073207931\n",
      "Recall: 0.7698819907644946\n",
      "F1 Score: 0.7663432073544433\n",
      "ROC-AUC Score: 0.8642538061264782\n"
     ]
    }
   ],
   "source": [
    "raw,a,b,c = encode_pipeline_L1(raw_df)\n",
    "# raw = raw.dropna()\n",
    "rfc_pipeline(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      4071\n",
      "           1       0.78      0.79      0.79      3898\n",
      "\n",
      "    accuracy                           0.79      7969\n",
      "   macro avg       0.79      0.79      0.79      7969\n",
      "weighted avg       0.79      0.79      0.79      7969\n",
      "\n",
      "Accuracy: 0.7894340569707617\n",
      "Precision: 0.7834525025536262\n",
      "Recall: 0.7870702924576706\n",
      "F1 Score: 0.7852572306117226\n",
      "ROC-AUC Score: 0.8808442034341945\n"
     ]
    }
   ],
   "source": [
    "rawRaw = raw.copy()\n",
    "rawRaw.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "rfc_pipeline(rawRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      4071\n",
      "           1       0.76      0.77      0.77      3898\n",
      "\n",
      "    accuracy                           0.77      7969\n",
      "   macro avg       0.77      0.77      0.77      7969\n",
      "weighted avg       0.77      0.77      0.77      7969\n",
      "\n",
      "Accuracy: 0.7707366043418246\n",
      "Precision: 0.7626172964747654\n",
      "Recall: 0.771421241662391\n",
      "F1 Score: 0.7669940058665986\n",
      "ROC-AUC Score: 0.8610885930707367\n"
     ]
    }
   ],
   "source": [
    "rawRawRaw = rawRaw.copy()\n",
    "rawRawRaw.drop(columns=[\"W_wt\"], inplace=True)\n",
    "rfc_pipeline(rawRawRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "enc_int_N_Outlier_filled_dropped_nulls\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62      3583\n",
      "           1       0.63      0.64      0.63      3584\n",
      "\n",
      "    accuracy                           0.63      7167\n",
      "   macro avg       0.63      0.63      0.63      7167\n",
      "weighted avg       0.63      0.63      0.63      7167\n",
      "\n",
      "Accuracy: 0.6288544718850286\n",
      "Precision: 0.6250676773145641\n",
      "Recall: 0.6442522321428571\n",
      "F1 Score: 0.6345149766419346\n",
      " \n",
      "enc_int_N_Outlier_filled_dropped_nulls\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      3583\n",
      "           1       0.69      0.69      0.69      3584\n",
      "\n",
      "    accuracy                           0.69      7167\n",
      "   macro avg       0.69      0.69      0.69      7167\n",
      "weighted avg       0.69      0.69      0.69      7167\n",
      "\n",
      "Accuracy: 0.6873168689828381\n",
      "Precision: 0.6876222408493993\n",
      "Recall: 0.6866629464285714\n",
      "F1 Score: 0.6871422588300992\n",
      "ROC-AUC Score: 0.7561991335572744\n",
      " \n",
      "enc_int_N_Outlier_filled_dropped_nulls\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      3583\n",
      "           1       0.63      0.65      0.64      3584\n",
      "\n",
      "    accuracy                           0.63      7167\n",
      "   macro avg       0.63      0.63      0.63      7167\n",
      "weighted avg       0.63      0.63      0.63      7167\n",
      "\n",
      "Accuracy: 0.6338774940700432\n",
      "Precision: 0.6296596434359806\n",
      "Recall: 0.650390625\n",
      "F1 Score: 0.6398572604995882\n",
      "ROC-AUC Score: 0.6772587285943543\n",
      " \n",
      "enc_1hot_N_Outlier_filled_dropped_nulls\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62      3583\n",
      "           1       0.62      0.64      0.63      3584\n",
      "\n",
      "    accuracy                           0.63      7167\n",
      "   macro avg       0.63      0.63      0.63      7167\n",
      "weighted avg       0.63      0.63      0.63      7167\n",
      "\n",
      "Accuracy: 0.6282963583089158\n",
      "Precision: 0.6248642779587406\n",
      "Recall: 0.6422991071428571\n",
      "F1 Score: 0.6334617501375894\n",
      " \n",
      "enc_1hot_N_Outlier_filled_dropped_nulls\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      3583\n",
      "           1       0.69      0.69      0.69      3584\n",
      "\n",
      "    accuracy                           0.69      7167\n",
      "   macro avg       0.69      0.69      0.69      7167\n",
      "weighted avg       0.69      0.69      0.69      7167\n",
      "\n",
      "Accuracy: 0.6938747035021627\n",
      "Precision: 0.694351230425056\n",
      "Recall: 0.6928013392857143\n",
      "F1 Score: 0.6935754189944134\n",
      "ROC-AUC Score: 0.756146919916969\n",
      " \n",
      "enc_1hot_N_Outlier_filled_dropped_nulls\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      3583\n",
      "           1       0.63      0.65      0.64      3584\n",
      "\n",
      "    accuracy                           0.63      7167\n",
      "   macro avg       0.64      0.63      0.63      7167\n",
      "weighted avg       0.64      0.63      0.63      7167\n",
      "\n",
      "Accuracy: 0.6348541928282405\n",
      "Precision: 0.6304993252361674\n",
      "Recall: 0.6517857142857143\n",
      "F1 Score: 0.6409658389353821\n",
      "ROC-AUC Score: 0.6773439991926159\n",
      " \n",
      "enc_int_Nyear_Outlier_filled_dropped_nulls_bool\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      3583\n",
      "           1       0.65      0.67      0.66      3584\n",
      "\n",
      "    accuracy                           0.66      7167\n",
      "   macro avg       0.66      0.66      0.66      7167\n",
      "weighted avg       0.66      0.66      0.66      7167\n",
      "\n",
      "Accuracy: 0.6581554346309474\n",
      "Precision: 0.6539087947882736\n",
      "Recall: 0.6721540178571429\n",
      "F1 Score: 0.662905888827738\n",
      " \n",
      "enc_int_Nyear_Outlier_filled_dropped_nulls_bool\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60      3583\n",
      "           1       0.61      0.62      0.62      3584\n",
      "\n",
      "    accuracy                           0.61      7167\n",
      "   macro avg       0.61      0.61      0.61      7167\n",
      "weighted avg       0.61      0.61      0.61      7167\n",
      "\n",
      "Accuracy: 0.6100181386912237\n",
      "Precision: 0.6069395500135538\n",
      "Recall: 0.6247209821428571\n",
      "F1 Score: 0.6157019111783308\n",
      "ROC-AUC Score: 0.6284853480971652\n",
      " \n",
      "enc_int_Nyear_Outlier_filled_dropped_nulls_bool\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      3583\n",
      "           1       0.65      0.67      0.66      3584\n",
      "\n",
      "    accuracy                           0.66      7167\n",
      "   macro avg       0.66      0.66      0.66      7167\n",
      "weighted avg       0.66      0.66      0.66      7167\n",
      "\n",
      "Accuracy: 0.6581554346309474\n",
      "Precision: 0.6539087947882736\n",
      "Recall: 0.6721540178571429\n",
      "F1 Score: 0.662905888827738\n",
      "ROC-AUC Score: 0.6618955365864598\n",
      " \n",
      "enc_1hot_Nyear_Outlier_filled_dropped_nulls_bool\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      3583\n",
      "           1       0.65      0.67      0.66      3584\n",
      "\n",
      "    accuracy                           0.66      7167\n",
      "   macro avg       0.66      0.66      0.66      7167\n",
      "weighted avg       0.66      0.66      0.66      7167\n",
      "\n",
      "Accuracy: 0.6581554346309474\n",
      "Precision: 0.6539087947882736\n",
      "Recall: 0.6721540178571429\n",
      "F1 Score: 0.662905888827738\n",
      " \n",
      "enc_1hot_Nyear_Outlier_filled_dropped_nulls_bool\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.61      3583\n",
      "           1       0.61      0.62      0.62      3584\n",
      "\n",
      "    accuracy                           0.61      7167\n",
      "   macro avg       0.61      0.61      0.61      7167\n",
      "weighted avg       0.61      0.61      0.61      7167\n",
      "\n",
      "Accuracy: 0.6119715362076182\n",
      "Precision: 0.6094303624965931\n",
      "Recall: 0.6238839285714286\n",
      "F1 Score: 0.6165724527781608\n",
      "ROC-AUC Score: 0.6310290595969059\n",
      " \n",
      "enc_1hot_Nyear_Outlier_filled_dropped_nulls_bool\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      3583\n",
      "           1       0.65      0.67      0.66      3584\n",
      "\n",
      "    accuracy                           0.66      7167\n",
      "   macro avg       0.66      0.66      0.66      7167\n",
      "weighted avg       0.66      0.66      0.66      7167\n",
      "\n",
      "Accuracy: 0.6581554346309474\n",
      "Precision: 0.6539087947882736\n",
      "Recall: 0.6721540178571429\n",
      "F1 Score: 0.662905888827738\n",
      "ROC-AUC Score: 0.6637303729665882\n",
      " \n",
      "enc_int_N_noOutlier_filled_dropped_nulls\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      3402\n",
      "           1       0.64      0.65      0.65      3343\n",
      "\n",
      "    accuracy                           0.65      6745\n",
      "   macro avg       0.65      0.65      0.65      6745\n",
      "weighted avg       0.65      0.65      0.65      6745\n",
      "\n",
      "Accuracy: 0.6456634544106745\n",
      "Precision: 0.6397770607216192\n",
      "Recall: 0.6524080167514209\n",
      "F1 Score: 0.6460308056872038\n",
      " \n",
      "enc_int_N_noOutlier_filled_dropped_nulls\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      3402\n",
      "           1       0.69      0.69      0.69      3343\n",
      "\n",
      "    accuracy                           0.69      6745\n",
      "   macro avg       0.69      0.69      0.69      6745\n",
      "weighted avg       0.69      0.69      0.69      6745\n",
      "\n",
      "Accuracy: 0.6892512972572276\n",
      "Precision: 0.6858420268256333\n",
      "Recall: 0.6883039186359557\n",
      "F1 Score: 0.6870707673932517\n",
      "ROC-AUC Score: 0.7537024023629535\n",
      " \n",
      "enc_int_N_noOutlier_filled_dropped_nulls\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      3402\n",
      "           1       0.64      0.66      0.65      3343\n",
      "\n",
      "    accuracy                           0.65      6745\n",
      "   macro avg       0.65      0.65      0.65      6745\n",
      "weighted avg       0.65      0.65      0.65      6745\n",
      "\n",
      "Accuracy: 0.6480355819125277\n",
      "Precision: 0.6420404573438874\n",
      "Recall: 0.655100209392761\n",
      "F1 Score: 0.648504589872668\n",
      "ROC-AUC Score: 0.6944672618717888\n",
      " \n",
      "enc_1hot_N_noOutlier_filled_dropped_nulls\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      3402\n",
      "           1       0.64      0.65      0.65      3343\n",
      "\n",
      "    accuracy                           0.64      6745\n",
      "   macro avg       0.64      0.64      0.64      6745\n",
      "weighted avg       0.64      0.64      0.64      6745\n",
      "\n",
      "Accuracy: 0.6447739065974796\n",
      "Precision: 0.6384907867797601\n",
      "Recall: 0.6530062817828298\n",
      "F1 Score: 0.6456669624371487\n",
      " \n",
      "enc_1hot_N_noOutlier_filled_dropped_nulls\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      3402\n",
      "           1       0.69      0.68      0.68      3343\n",
      "\n",
      "    accuracy                           0.69      6745\n",
      "   macro avg       0.69      0.69      0.69      6745\n",
      "weighted avg       0.69      0.69      0.69      6745\n",
      "\n",
      "Accuracy: 0.6879169755374351\n",
      "Precision: 0.6863335340156532\n",
      "Recall: 0.6820221358061621\n",
      "F1 Score: 0.6841710427606902\n",
      "ROC-AUC Score: 0.7567196664065745\n",
      " \n",
      "enc_1hot_N_noOutlier_filled_dropped_nulls\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      3402\n",
      "           1       0.64      0.65      0.65      3343\n",
      "\n",
      "    accuracy                           0.65      6745\n",
      "   macro avg       0.65      0.65      0.65      6745\n",
      "weighted avg       0.65      0.65      0.65      6745\n",
      "\n",
      "Accuracy: 0.6472942920681987\n",
      "Precision: 0.6415149735760423\n",
      "Recall: 0.6536045468142387\n",
      "F1 Score: 0.6475033338272337\n",
      "ROC-AUC Score: 0.6945061262374388\n",
      " \n",
      "enc_int_Nyear_noOutlier_filled_dropped_nulls_bool\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      3402\n",
      "           1       0.66      0.67      0.66      3343\n",
      "\n",
      "    accuracy                           0.66      6745\n",
      "   macro avg       0.66      0.66      0.66      6745\n",
      "weighted avg       0.66      0.66      0.66      6745\n",
      "\n",
      "Accuracy: 0.6630096367679763\n",
      "Precision: 0.6572604350382129\n",
      "Recall: 0.668860305115166\n",
      "F1 Score: 0.6630096367679763\n",
      " \n",
      "enc_int_Nyear_noOutlier_filled_dropped_nulls_bool\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61      3402\n",
      "           1       0.61      0.61      0.61      3343\n",
      "\n",
      "    accuracy                           0.61      6745\n",
      "   macro avg       0.61      0.61      0.61      6745\n",
      "weighted avg       0.61      0.61      0.61      6745\n",
      "\n",
      "Accuracy: 0.612008895478132\n",
      "Precision: 0.6079072532699168\n",
      "Recall: 0.6117259946156147\n",
      "F1 Score: 0.6098106455941553\n",
      "ROC-AUC Score: 0.6312934113645385\n",
      " \n",
      "enc_int_Nyear_noOutlier_filled_dropped_nulls_bool\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      3402\n",
      "           1       0.66      0.67      0.66      3343\n",
      "\n",
      "    accuracy                           0.66      6745\n",
      "   macro avg       0.66      0.66      0.66      6745\n",
      "weighted avg       0.66      0.66      0.66      6745\n",
      "\n",
      "Accuracy: 0.6630096367679763\n",
      "Precision: 0.6572604350382129\n",
      "Recall: 0.668860305115166\n",
      "F1 Score: 0.6630096367679763\n",
      "ROC-AUC Score: 0.6685504453311149\n",
      " \n",
      "enc_1hot_Nyear_noOutlier_filled_dropped_nulls_bool\n",
      "Linear Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      3402\n",
      "           1       0.66      0.67      0.66      3343\n",
      "\n",
      "    accuracy                           0.66      6745\n",
      "   macro avg       0.66      0.66      0.66      6745\n",
      "weighted avg       0.66      0.66      0.66      6745\n",
      "\n",
      "Accuracy: 0.6630096367679763\n",
      "Precision: 0.6572604350382129\n",
      "Recall: 0.668860305115166\n",
      "F1 Score: 0.6630096367679763\n",
      " \n",
      "enc_1hot_Nyear_noOutlier_filled_dropped_nulls_bool\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62      3402\n",
      "           1       0.61      0.62      0.61      3343\n",
      "\n",
      "    accuracy                           0.62      6745\n",
      "   macro avg       0.62      0.62      0.62      6745\n",
      "weighted avg       0.62      0.62      0.62      6745\n",
      "\n",
      "Accuracy: 0.6160118606375092\n",
      "Precision: 0.6116217017491847\n",
      "Recall: 0.617110379898295\n",
      "F1 Score: 0.6143537820131031\n",
      "ROC-AUC Score: 0.6354683411053272\n",
      " \n",
      "enc_1hot_Nyear_noOutlier_filled_dropped_nulls_bool\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      3402\n",
      "           1       0.66      0.67      0.66      3343\n",
      "\n",
      "    accuracy                           0.66      6745\n",
      "   macro avg       0.66      0.66      0.66      6745\n",
      "weighted avg       0.66      0.66      0.66      6745\n",
      "\n",
      "Accuracy: 0.6630096367679763\n",
      "Precision: 0.6572604350382129\n",
      "Recall: 0.668860305115166\n",
      "F1 Score: 0.6630096367679763\n",
      "ROC-AUC Score: 0.6680078829595232\n",
      " \n",
      "enc_int_N_Outlier_dropped_nulls\n",
      "Linear Support Vector Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68      1511\n",
      "           1       0.74      0.01      0.03      1449\n",
      "\n",
      "    accuracy                           0.51      2960\n",
      "   macro avg       0.63      0.50      0.35      2960\n",
      "weighted avg       0.62      0.51      0.36      2960\n",
      "\n",
      "Accuracy: 0.5148648648648648\n",
      "Precision: 0.7407407407407407\n",
      "Recall: 0.013802622498274672\n",
      "F1 Score: 0.02710027100271003\n",
      " \n",
      "enc_int_N_Outlier_dropped_nulls\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      1511\n",
      "           1       0.88      0.88      0.88      1449\n",
      "\n",
      "    accuracy                           0.88      2960\n",
      "   macro avg       0.88      0.88      0.88      2960\n",
      "weighted avg       0.88      0.88      0.88      2960\n",
      "\n",
      "Accuracy: 0.8807432432432433\n",
      "Precision: 0.8774104683195593\n",
      "Recall: 0.8792270531400966\n",
      "F1 Score: 0.8783178214408824\n",
      "ROC-AUC Score: 0.9543209470553873\n",
      " \n",
      "enc_int_N_Outlier_dropped_nulls\n",
      "Logistic regression Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60      1511\n",
      "           1       0.59      0.59      0.59      1449\n",
      "\n",
      "    accuracy                           0.60      2960\n",
      "   macro avg       0.60      0.60      0.60      2960\n",
      "weighted avg       0.60      0.60      0.60      2960\n",
      "\n",
      "Accuracy: 0.5966216216216216\n",
      "Precision: 0.5871496924128503\n",
      "Recall: 0.5928226363008972\n",
      "F1 Score: 0.5899725274725275\n",
      "ROC-AUC Score: 0.6314736332001029\n",
      " \n",
      "enc_1hot_N_Outlier_dropped_nulls\n",
      "Linear Support Vector Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.99      0.68      1511\n",
      "           1       0.70      0.02      0.04      1449\n",
      "\n",
      "    accuracy                           0.52      2960\n",
      "   macro avg       0.61      0.51      0.36      2960\n",
      "weighted avg       0.60      0.52      0.36      2960\n",
      "\n",
      "Accuracy: 0.5158783783783784\n",
      "Precision: 0.7\n",
      "Recall: 0.01932367149758454\n",
      "F1 Score: 0.03760913364674278\n",
      " \n",
      "enc_1hot_N_Outlier_dropped_nulls\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      1511\n",
      "           1       0.88      0.88      0.88      1449\n",
      "\n",
      "    accuracy                           0.88      2960\n",
      "   macro avg       0.88      0.88      0.88      2960\n",
      "weighted avg       0.88      0.88      0.88      2960\n",
      "\n",
      "Accuracy: 0.8827702702702702\n",
      "Precision: 0.8810511756569848\n",
      "Recall: 0.8792270531400966\n",
      "F1 Score: 0.8801381692573402\n",
      "ROC-AUC Score: 0.9558795654960015\n",
      " \n",
      "enc_1hot_N_Outlier_dropped_nulls\n",
      "Logistic regression Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58      1511\n",
      "           1       0.58      0.66      0.62      1449\n",
      "\n",
      "    accuracy                           0.60      2960\n",
      "   macro avg       0.60      0.60      0.60      2960\n",
      "weighted avg       0.60      0.60      0.60      2960\n",
      "\n",
      "Accuracy: 0.6006756756756757\n",
      "Precision: 0.5815516188149054\n",
      "Recall: 0.6570048309178744\n",
      "F1 Score: 0.6169799092676604\n",
      "ROC-AUC Score: 0.6304637854719861\n",
      " \n",
      "enc_int_Nyear_Outlier_dropped_nulls_bool\n",
      "Linear Support Vector Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.19      0.28      1511\n",
      "           1       0.50      0.85      0.63      1449\n",
      "\n",
      "    accuracy                           0.51      2960\n",
      "   macro avg       0.54      0.52      0.46      2960\n",
      "weighted avg       0.54      0.51      0.45      2960\n",
      "\n",
      "Accuracy: 0.5138513513513514\n",
      "Precision: 0.5020292207792207\n",
      "Recall: 0.8536922015182885\n",
      "F1 Score: 0.6322514694607718\n",
      " \n",
      "enc_int_Nyear_Outlier_dropped_nulls_bool\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1511\n",
      "           1       0.79      0.81      0.80      1449\n",
      "\n",
      "    accuracy                           0.80      2960\n",
      "   macro avg       0.80      0.80      0.80      2960\n",
      "weighted avg       0.80      0.80      0.80      2960\n",
      "\n",
      "Accuracy: 0.7989864864864865\n",
      "Precision: 0.7861930294906166\n",
      "Recall: 0.8095238095238095\n",
      "F1 Score: 0.7976878612716763\n",
      "ROC-AUC Score: 0.8830981360978771\n",
      " \n",
      "enc_int_Nyear_Outlier_dropped_nulls_bool\n",
      "Logistic regression Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.58      0.59      1511\n",
      "           1       0.57      0.59      0.58      1449\n",
      "\n",
      "    accuracy                           0.58      2960\n",
      "   macro avg       0.58      0.58      0.58      2960\n",
      "weighted avg       0.58      0.58      0.58      2960\n",
      "\n",
      "Accuracy: 0.5827702702702703\n",
      "Precision: 0.5721024258760108\n",
      "Recall: 0.5859213250517599\n",
      "F1 Score: 0.5789294237981589\n",
      "ROC-AUC Score: 0.60033140909612\n",
      " \n",
      "enc_1hot_Nyear_Outlier_dropped_nulls_bool\n",
      "Linear Support Vector Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.99      0.67      1511\n",
      "           1       0.50      0.01      0.01      1449\n",
      "\n",
      "    accuracy                           0.51      2960\n",
      "   macro avg       0.51      0.50      0.34      2960\n",
      "weighted avg       0.51      0.51      0.35      2960\n",
      "\n",
      "Accuracy: 0.510472972972973\n",
      "Precision: 0.5\n",
      "Recall: 0.006211180124223602\n",
      "F1 Score: 0.012269938650306749\n",
      " \n",
      "enc_1hot_Nyear_Outlier_dropped_nulls_bool\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1511\n",
      "           1       0.79      0.80      0.80      1449\n",
      "\n",
      "    accuracy                           0.80      2960\n",
      "   macro avg       0.80      0.80      0.80      2960\n",
      "weighted avg       0.80      0.80      0.80      2960\n",
      "\n",
      "Accuracy: 0.797972972972973\n",
      "Precision: 0.7888662593346911\n",
      "Recall: 0.8019323671497585\n",
      "F1 Score: 0.7953456536618754\n",
      "ROC-AUC Score: 0.879790667837743\n",
      " \n",
      "enc_1hot_Nyear_Outlier_dropped_nulls_bool\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.58      0.59      1511\n",
      "           1       0.57      0.59      0.58      1449\n",
      "\n",
      "    accuracy                           0.58      2960\n",
      "   macro avg       0.58      0.58      0.58      2960\n",
      "weighted avg       0.58      0.58      0.58      2960\n",
      "\n",
      "Accuracy: 0.5824324324324325\n",
      "Precision: 0.5716207128446537\n",
      "Recall: 0.5866114561766735\n",
      "F1 Score: 0.5790190735694822\n",
      "ROC-AUC Score: 0.6030334711311893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for df in dataframes:\n",
    "    print(\" \\n\"+dataframe_names[i])\n",
    "    lin_svc_pipeline(df)\n",
    "    print(\" \\n\"+dataframe_names[i])\n",
    "    rfc_pipeline(df)\n",
    "    print(\" \\n\"+dataframe_names[i])\n",
    "    logReg_pipeline(df)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66      1444\n",
      "           1       0.86      0.02      0.03      1516\n",
      "\n",
      "    accuracy                           0.49      2960\n",
      "   macro avg       0.67      0.51      0.34      2960\n",
      "weighted avg       0.68      0.49      0.34      2960\n",
      "\n",
      "Accuracy: 0.4945945945945946\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 0.0158311345646438\n",
      "F1 Score: 0.031088082901554404\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91      1444\n",
      "           1       0.92      0.89      0.91      1516\n",
      "\n",
      "    accuracy                           0.91      2960\n",
      "   macro avg       0.91      0.91      0.91      2960\n",
      "weighted avg       0.91      0.91      0.91      2960\n",
      "\n",
      "Accuracy: 0.9060810810810811\n",
      "Precision: 0.9199457259158752\n",
      "Recall: 0.8944591029023746\n",
      "F1 Score: 0.9070234113712374\n",
      "ROC-AUC Score: 0.9702487867182189\n",
      "Logistic regression Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1444\n",
      "           1       0.66      0.62      0.64      1516\n",
      "\n",
      "    accuracy                           0.64      2960\n",
      "   macro avg       0.64      0.64      0.64      2960\n",
      "weighted avg       0.64      0.64      0.64      2960\n",
      "\n",
      "Accuracy: 0.643581081081081\n",
      "Precision: 0.6631280962491154\n",
      "Recall: 0.6180738786279684\n",
      "F1 Score: 0.6398088084670536\n",
      "ROC-AUC Score: 0.6882299790233813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erich\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "rawRaw = rawRaw.dropna()\n",
    "lin_svc_pipeline(rawRaw)\n",
    "# svc_pipeline(rawRaw)\n",
    "rfc_pipeline(rawRaw)\n",
    "logReg_pipeline(rawRaw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
